{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOznRQUP7hM4WrDkEiGfOm6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johyunkang/MLwithPythonCookbook/blob/main/13_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.1 직선 학습하기\n",
        "\n",
        "과제 : 특성과 타깃 벡터 사이의 선형 관계를 표현하는 모델을 훈련하고 싶음\n",
        "\n",
        "해결 : 선형 회귀를 사용함(`LinearRegression`)"
      ],
      "metadata": {
        "id": "8HxDGLFpCjyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyiGPEu7CLUa",
        "outputId": "c8acb6b8-61f6-42c2-98ca-f505ffb1c011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature shape: (506, 2)\n",
            "feature sample: [[6.320e-03 1.800e+01]\n",
            " [2.731e-02 0.000e+00]\n",
            " [2.729e-02 0.000e+00]]\n",
            "target shape: (506,)\n",
            "target sample: [24.  21.6 34.7]\n",
            "feature name: ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
            " 'B' 'LSTAT']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "boston = load_boston()\n",
        "x = boston.data[:, :2] # 특성 2개만 선택\n",
        "print('feature shape:', x.shape)\n",
        "print('feature sample:', x[:3])\n",
        "y = boston.target\n",
        "print('target shape:', y.shape)\n",
        "print('target sample:', y[:3])\n",
        "print('feature name:', boston.feature_names)\n",
        "\n",
        "\n",
        "lr = LinearRegression()\n",
        "model = lr.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 절편(intercept) = 편향(bias)\n",
        "print('Intercept(=bias) :', model.intercept_)\n",
        "print('coef :', model.coef_)\n",
        "# dir(model)\n",
        "\n",
        "print('\\n실제값:', y[0] * 1000) # 보스턴 주택가격 단위가 천 달러라, 1000을 곱해줌\n",
        "print('예측값:', model.predict(x)[0] * 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMUsQRaWDdex",
        "outputId": "b4a41c73-f55b-453c-9e25-c67a9be28f80"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept(=bias) : 22.485628113468223\n",
            "coef : [-0.35207832  0.11610909]\n",
            "\n",
            "실제값: 24000.0\n",
            "예측값: 24573.366631705547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.2 교차 특성 다루기\n",
        "\n",
        "과제 : 타깃 변수에 영향을 미치면서 다른 특성에 의존하는 특성이 있음\n",
        "\n",
        "해결 : 사이킷런의 `PolynomialFeatures` 클래스로 교차항(interactive term)을 만들어 의존성을 잡아냅니다."
      ],
      "metadata": {
        "id": "QaCcCHChFi-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "boston = load_boston()\n",
        "x = boston.data[:, :2]\n",
        "y = boston.target\n",
        "class_name = boston.feature_names\n",
        "# dir(boston)\n",
        "print('class name 2개:', class_name[:2])\n",
        "\n",
        "# 교차항을 생성\n",
        "# degree : 교차항을 만들 때 최대 특성의 수\n",
        "# include_bias : 기본적으로 절편(bias)이라 부르는 1로 채워진 특성을 추가하는데, False 이면 그렇게 하지 않음\n",
        "# interaction_only : True 지정 시 오직 교차항만 반환 \n",
        "interaction = PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)\n",
        "\n",
        "features_interaction = interaction.fit_transform(x)\n",
        "print('feature interaction sample:', features_interaction[:3])\n",
        "\n",
        "lr = LinearRegression()\n",
        "model = lr.fit(features_interaction, y)\n"
      ],
      "metadata": {
        "id": "-iM7XkivFxlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c958072-0712-47ec-acab-27d7c61a6aad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class name 2개: ['CRIM' 'ZN']\n",
            "feature interaction sample: [[6.3200e-03 1.8000e+01 1.1376e-01]\n",
            " [2.7310e-02 0.0000e+00 0.0000e+00]\n",
            " [2.7290e-02 0.0000e+00 0.0000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('첫 번째 샘플의 특성값 확인:', x[0])\n",
        "\n",
        "import numpy as np\n",
        "#각 샘플에서 첫 번째와 두 번째 특성을 곱한다.\n",
        "interaction_term = np.multiply(x[:, 0], x[:, 1])\n",
        "\n",
        "print('첫 번째 샘플의 교차항 확인:', interaction_term[0])\n",
        "print('위의 \"feature interaction sample\" 값과 \"첫번째 샘플의 특성값\" 과 바로 위 \"교차항 확인\" 값이 동일한 것을 확인할 수 있다')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC3MB0rYntvr",
        "outputId": "2c2fb52f-31b2-4a9b-85b6-ff9cd2882587"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 샘플의 특성값 확인: [6.32e-03 1.80e+01]\n",
            "첫 번째 샘플의 교차항 확인: 0.11376\n",
            "위의 \"feature interaction sample\" 값과 \"첫번째 샘플의 특성값\" 과 바로 위 \"교차항 확인\" 값이 동일한 것을 확인할 수 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.4 규제로 분산 줄이기\n",
        "\n",
        "과제 : 선형 회귀의 분산을 줄이고 싶습니다.\n",
        "\n",
        "해결 : 리지 회귀나 라소 회귀와 같이 축소 페널티( 또는 규제 regularization)가 포함된 학습 알고리즘을 사용"
      ],
      "metadata": {
        "id": "rUWiXGsTpXBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "boston = load_boston()\n",
        "x = boston.data\n",
        "y = boston.target\n",
        "class_name = boston.feature_names\n",
        "print('class_name sample:', class_name[:2])\n",
        "\n",
        "# 표준화\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# alpha 값을 지정한 리지 회귀 생성\n",
        "ridge = Ridge(alpha=0.5)\n",
        "\n",
        "model = ridge.fit(x_scaled, y)\n"
      ],
      "metadata": {
        "id": "zXswBYfCpirt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191e04a6-76d4-47a8-f4de-7a4df0607a09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class_name sample: ['CRIM' 'ZN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "표준 선형 회귀 모델에서는 정답(y)와 예측(y_hat) 사이의 제곱 오차 합 (Sum of Squared Error) 또는 잔차 제곱 합(Residual Sum of Squared)을 최소화 하기 위해 훈련함\n",
        "\n",
        "$RSS = \\displaystyle \\sum_{i=1}^n(y_i - \\hat{y}_i)^2$\n",
        "\n",
        "\n",
        "- Ridge 회귀 : 축소 페널티는 모든 계수의 제곱합에 튜닝 파라미터를 곱한 것\n",
        "\n",
        "    $RSS + \\alpha \\displaystyle \\sum_{j=1}^p \\hat{\\beta}_j^2$\n",
        "\n",
        "    - b_hat : p 특성의 j번째 계수\n",
        "    - a : 하이퍼파라미터\n",
        "\n",
        "- Lasso 회귀 : 축소 페널티가 모든 계수의 절댓값 합에 튜닝 하이퍼파라미터를 곱한 것\n",
        "\n",
        "    $\\dfrac {1} {2n} RSS + \\alpha \\displaystyle \\sum_{j=1}^p \\left|\\hat{\\beta}_j \\right|$\n",
        "\n",
        "    - n : 샘플의 갯수\n",
        "\n",
        "\n",
        "일반적으로 라소가 더 이해하기 쉬운 모델을 만듦. 대신 리지 회귀가 라소 보다 더 좋은 예측을 만듦. 리지와 라소 사이 균형을 맞추고 싶으면 **엘라스틱 넷**을 사용하면 됨\n",
        "\n",
        "- 하이퍼파라미터 a (alpha) : 계수를 얼마나 불리하게 만들지 조절. a 값이 클수록 더 간단한 모델을 만듦. 이상적인 a를 구하려면 `RidgeCV` 클래스를 사용\n"
      ],
      "metadata": {
        "id": "LHtciUrXHvor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "rcv = RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
        "model_cv = rcv.fit(x_scaled, y)\n",
        "\n",
        "print('coef :', model_cv.coef_)\n",
        "\n",
        "print('\\nalpha value:', model_cv.alpha_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yboLbPh5u2K",
        "outputId": "da12a03d-cdd9-4505-a85b-03f015800ac5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coef : [-0.91987132  1.06646104  0.11738487  0.68512693 -2.02901013  2.68275376\n",
            "  0.01315848 -3.07733968  2.59153764 -2.0105579  -2.05238455  0.84884839\n",
            " -3.73066646]\n",
            "\n",
            "alpha value: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.5 라소 회귀로 특성 줄이기\n",
        "\n",
        "과제 : 특성의 수를 줄여서 선영 회귀 모델을 단순하게 만들고 싶음\n",
        "\n",
        "해결 : 라소 회귀를 사용합니다."
      ],
      "metadata": {
        "id": "sw91St7e-n0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# set_printoptions : 지수를 실수로 표현\n",
        "# suppress : True 면 무조건 실수, False면 엄청 작은 수는 그대로 지수로 표현\n",
        "np.set_printoptions(precision=5, suppress=False) \n",
        "\n",
        "# 지수 표현 없애기\n",
        "# pd.options.display.float_format='{:.5f}'.format\n",
        "\n",
        "# 지수표현 원복\n",
        "# pd.reset_option('display.float_format')\n",
        "\n",
        "boston = load_boston()\n",
        "x = boston.data\n",
        "y = boston.target\n",
        "\n",
        "print('x sample:', x[:3])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "print('\\nx_scaled sample:', x_scaled[:3])\n",
        "\n",
        "# a 값을 지정한 라쏘 회귀\n",
        "lasso = Lasso(alpha=0.5)\n",
        "\n",
        "model = lasso.fit(x_scaled, y)\n",
        "\n",
        "print('\\n\\n모델 계수:', model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w3yZ-Y9-t__",
        "outputId": "f0a6de61-f8c6-4cc8-c75d-8dd5e65d7b0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x sample: [[6.3200e-03 1.8000e+01 2.3100e+00 0.0000e+00 5.3800e-01 6.5750e+00\n",
            "  6.5200e+01 4.0900e+00 1.0000e+00 2.9600e+02 1.5300e+01 3.9690e+02\n",
            "  4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 6.4210e+00\n",
            "  7.8900e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9690e+02\n",
            "  9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 0.0000e+00 4.6900e-01 7.1850e+00\n",
            "  6.1100e+01 4.9671e+00 2.0000e+00 2.4200e+02 1.7800e+01 3.9283e+02\n",
            "  4.0300e+00]]\n",
            "\n",
            "x_scaled sample: [[-0.41978  0.28483 -1.28791 -0.2726  -0.14422  0.41367 -0.12001  0.14021\n",
            "  -0.98284 -0.66661 -1.459    0.44105 -1.07556]\n",
            " [-0.41734 -0.48772 -0.59338 -0.2726  -0.74026  0.19427  0.36717  0.55716\n",
            "  -0.86788 -0.98733 -0.30309  0.44105 -0.49244]\n",
            " [-0.41734 -0.48772 -0.59338 -0.2726  -0.74026  1.28271 -0.26581  0.55716\n",
            "  -0.86788 -0.98733 -0.30309  0.39643 -1.20873]]\n",
            "\n",
            "\n",
            "모델 계수: [-0.11526  0.      -0.       0.39708 -0.       2.97426 -0.      -0.17057\n",
            " -0.      -0.      -1.59845  0.54314 -3.66614]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "라소 회귀 페널티 특성은 모델의 계수를 0까지 축소시킬 수 있다는 것\n",
        "\n",
        "위에서 `alpha`를 0.5로 지정하여 많은 계수가 0이 되었음. 즉 0에 해당하는 특성은 모델에서 사용되지 않는 다는 의미"
      ],
      "metadata": {
        "id": "1d_KQ69hCXyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a 값이 너무 크게 증가하면 어떤 특성도 사용되지 않음\n",
        "lasso_a10 = Lasso(alpha=10)\n",
        "\n",
        "model_a10 = lasso_a10.fit(x_scaled, y)\n",
        "print('a 값이 증가한 모델 계수:', model_a10.coef_)\n",
        "print('\\n a 값이 너무 크면 어떠한 특성도 사용되지 않음')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3YgN2wXCEGb",
        "outputId": "bf244d13-73b6-4621-d78c-b95ac178f75e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a 값이 증가한 모델 계수: [-0.  0. -0.  0. -0.  0. -0.  0. -0. -0. -0.  0. -0.]\n",
            "\n",
            " a 값이 너무 크면 어떠한 특성도 사용되지 않음\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "라소의 a 값을 쉽게 찾기 위해 `LassoCV` 클래스를 이용 가능\n",
        "\n",
        "`cv` 옵션을 통해 n 폴드 교차검증 사용할 수 있음"
      ],
      "metadata": {
        "id": "p1-szuvTB65y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "lasso_cv = LassoCV(alphas=[0.1, 1.0, 10], cv=5)\n",
        "\n",
        "model_cv = lasso_cv.fit(x_scaled, y)\n",
        "\n",
        "print('계수:', model_cv.coef_)\n",
        "\n",
        "print('\\n 최고의 a값:', model_cv.alpha_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5g326RcDFst",
        "outputId": "3d01d4f3-2f61-49dd-9e46-7af7d4f04adc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "계수: [-0.6323   0.70841 -0.       0.65761 -1.57419  2.82627 -0.      -2.42208\n",
            "  1.19594 -0.84647 -1.92249  0.76217 -3.72618]\n",
            "\n",
            " 최고의 a값: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`LassoCV`는 탐색할 a 값을 명시적으로 지정하지 않고, `n_alphas` 를 통해 자동으로 탐색 대상 값을 생성할 수 있음\n",
        "\n",
        "`n_alphas`의 디폴트 값은 100이며, 이를 1,000 개로 늘려 테스트 해보자."
      ],
      "metadata": {
        "id": "HUxfPsZrDeer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_cv_1000 = LassoCV(n_alphas=1000, cv=5)\n",
        "\n",
        "model_cv_1000 = lasso_cv_1000.fit(x_scaled, y)\n",
        "\n",
        "print('1000개의 후보 중 선정된 a :', model_cv_1000.alpha_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzoCQ8mxDrn9",
        "outputId": "e15fc0dd-800b-4038-b7c1-9e17eb62e6e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000개의 후보 중 선정된 a : 0.15326173083090813\n"
          ]
        }
      ]
    }
  ]
}